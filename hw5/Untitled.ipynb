{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import permutation\n",
    "from keras.layers import Input, Embedding, LSTM, Dense,Dot, Flatten, Add, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "assert Input and Embedding and LSTM and Dense and Dot and Flatten and Add\n",
    "assert Model\n",
    "assert np_utils and permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager:\n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "        self.id = {}\n",
    "        \n",
    "    def read_data(self, path, name, with_label=True, read_id=False):\n",
    "        \n",
    "        if with_label:\n",
    "            f = pd.read_csv(path)\n",
    "            uid = np.array(f.iloc[:]['UserID']).reshape(-1,1)\n",
    "            mid = np.array(f.iloc[:]['MovieID']).reshape(-1,1)\n",
    "            rat = np.array(f.iloc[:]['Rating']).reshape(-1,1)\n",
    "            #self.Data_normalization(rat)\n",
    "            data = permutation(np.hstack((uid, mid, rat)))\n",
    "            X = data[:, 0:2]\n",
    "            Y = data[:, 2].reshape(-1,1)\n",
    "            self.data[name] = [X, Y]\n",
    "            \n",
    "        elif not read_id:\n",
    "            f = pd.read_csv(path)\n",
    "            uid = np.array(f.iloc[:]['UserID']).reshape(-1,1)\n",
    "            mid = np.array(f.iloc[:]['MovieID']).reshape(-1,1)\n",
    "            X = np.hstack((uid, mid))\n",
    "            self.data[name] = [X]\n",
    "            \n",
    "        else:\n",
    "            ff = open(path, 'r', encoding='latin-1')\n",
    "            id_n=[]\n",
    "            next(ff)\n",
    "            for line in ff:\n",
    "                id_n.append(int(line.split('::', 1)[0]))\n",
    "            maxid = max(id_n)\n",
    "            self.id[name] = [id_n, maxid]\n",
    "            ff.close()\n",
    "    \n",
    "    def Data_normalization(self, arr): # normalize train rating\n",
    "        self.train_rating_std = arr.std()\n",
    "        self.train_rating_mean = arr.mean()\n",
    "        arr = ((arr - arr.mean()) / arr.std())\n",
    "            \n",
    "            \n",
    "    def build_model_0(self):\n",
    "        u_input = Input(shape=(1,), name='user_input')\n",
    "        m_input = Input(shape=(1,), name='movie_input')\n",
    "            \n",
    "        e1_u = Flatten()(Embedding(output_dim=128, input_dim=self.id['user'][1],  input_length=1)(u_input))\n",
    "        e2_u = Flatten()(Embedding(output_dim=1,  input_dim=self.id['user'][1],  input_length=1)(u_input))\n",
    "        e1_m = Flatten()(Embedding(output_dim=128, input_dim=self.id['movie'][1], input_length=1)(m_input))\n",
    "        e2_m = Flatten()(Embedding(output_dim=1,  input_dim=self.id['movie'][1], input_length=1)(m_input))\n",
    "            \n",
    "        \n",
    "        output = Add(name='output')([e2_u, e2_m, Dot(1)([e1_m, e1_u])])\n",
    "        model = Model(inputs=[u_input, m_input], outputs=[output])\n",
    "        #model.compile('adam', 'categorical_crossentropy')\n",
    "        self.model_0 = model\n",
    "    \n",
    "    def build_model_TA(self, n_users=6040, n_items=3883, latent_dim=1024):\n",
    "        user_input = Input(shape=[1], name='user_input')\n",
    "        item_input = Input(shape=[1], name='movie_input')\n",
    "        user_vec = Embedding(n_users, latent_dim, \n",
    "                             embeddings_initializer='random_normal')(user_input)\n",
    "        user_vec = Flatten()(user_vec)\n",
    "        item_vec = Embedding(n_users, latent_dim, \n",
    "                             embeddings_initializer='random_normal')(item_input)\n",
    "        item_vec = Flatten()(item_vec)\n",
    "        user_bias = Embedding(n_users, 1, embeddings_initializer='zeros')(user_input)\n",
    "        user_bias = Flatten()(user_bias)\n",
    "        item_bias = Embedding(n_items, 1, embeddings_initializer='zeros')(item_input)\n",
    "        item_bias = Flatten()(item_bias)\n",
    "        r_hat = Dot(axes=1)([user_vec, item_vec])\n",
    "        r_hat = Add(name='output')([r_hat, user_bias, item_bias])\n",
    "        model = Model([user_input, item_input], r_hat)\n",
    "        self.model_1 = model\n",
    "        # get embedding\n",
    "        user_emb = np.array(model.layers[2].get_weights()).squeeze()\n",
    "        movie_emb = np.array(model.layers[3].get_weights()).squeeze()\n",
    "        print ('user embedding shape:', user_emb.shape)\n",
    "        print ('movie embedding shape:', movie_emb.shape)\n",
    "        np.save('save/user_emb_1.npy', user_emb)\n",
    "        np.save('save/movie_emb_1.npy', movie_emb)\n",
    "        \n",
    "    def build_model_TA_no_bias(self, n_users=6040, n_items=3883, latent_dim=1024):\n",
    "        user_input = Input(shape=[1], name='user_input')\n",
    "        item_input = Input(shape=[1], name='movie_input')\n",
    "        user_vec = Embedding(n_users, latent_dim, \n",
    "                             embeddings_initializer='random_normal')(user_input)\n",
    "        user_vec = Flatten()(user_vec)\n",
    "        item_vec = Embedding(n_users, latent_dim, \n",
    "                             embeddings_initializer='random_normal')(item_input)\n",
    "        item_vec = Flatten()(item_vec)\n",
    "        #user_bias = Embedding(n_users, 1, embeddings_initializer='zeros')(user_input)\n",
    "        #user_bias = Flatten()(user_bias)\n",
    "        #item_bias = Embedding(n_items, 1, embeddings_initializer='zeros')(item_input)\n",
    "        #item_bias = Flatten()(item_bias)\n",
    "        r_hat = Dot(axes=1, name='output')([user_vec, item_vec])\n",
    "        #r_hat = Add(name='output')([r_hat, user_bias, item_bias])\n",
    "        model = Model([user_input, item_input], r_hat)\n",
    "        self.model_no_bias = model\n",
    "        # get embedding\n",
    "        user_emb = np.array(model.layers[2].get_weights()).squeeze()\n",
    "        movie_emb = np.array(model.layers[3].get_weights()).squeeze()\n",
    "        print ('user embedding shape:', user_emb.shape)\n",
    "        print ('movie embedding shape:', movie_emb.shape)\n",
    "        np.save('save/user_emb_1.npy', user_emb)\n",
    "        np.save('save/movie_emb_1.npy', movie_emb)\n",
    "        \n",
    "    def build_model_TA_DNN(self, n_users=6040, n_items=3883, latent_dim=1024):\n",
    "        user_input = Input(shape=[1], name='user_input')\n",
    "        item_input = Input(shape=[1], name='movie_input')\n",
    "        user_vec = Embedding(n_users, latent_dim, \n",
    "                             embeddings_initializer='random_normal')(user_input)\n",
    "        user_vec = Flatten()(user_vec)\n",
    "        item_vec = Embedding(n_users, latent_dim, \n",
    "                             embeddings_initializer='random_normal')(item_input)\n",
    "        item_vec = Flatten()(item_vec)\n",
    "        merge_vec = Concatenate()([user_vec, item_vec])\n",
    "        hidden = Dense(128, activation='relu')(merge_vec)\n",
    "        hidden = Dense(64, activation='relu')(hidden)\n",
    "        output = Dense(1, name='output')(hidden)\n",
    "        model = Model([user_input, item_input], output)\n",
    "        self.model_dnn = model\n",
    "        # get embedding\n",
    "        user_emb = np.array(model.layers[2].get_weights()).squeeze()\n",
    "        movie_emb = np.array(model.layers[3].get_weights()).squeeze()\n",
    "        print ('user embedding shape:', user_emb.shape)\n",
    "        print ('movie embedding shape:', movie_emb.shape)\n",
    "        np.save('save/user_emb_2.npy', user_emb)\n",
    "        np.save('save/movie_emb_2.npy', movie_emb)\n",
    "            \n",
    "    def MSE(self, y_true, y_pred):\n",
    "        return (K.mean(K.square(y_pred - y_true), axis=-1)) \n",
    "    \n",
    "    def write_file(self, test, path):\n",
    "        idx = np.array([[j for j in range(1, len(test)+1)]]).T\n",
    "        test = np.hstack((idx, test))\n",
    "        \n",
    "        out = pd.DataFrame(test, columns=['TestDataID', 'Rating'])\n",
    "        out['TestDataID'] = out['TestDataID'].astype(int)\n",
    "        out.to_csv(path, index=False)\n",
    "                                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import sys\n",
    "#from util import DataManager\n",
    "import keras \n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "sys.path.append('./data')\n",
    "\n",
    "n_batch=2048\n",
    "\n",
    "def main(_model):\n",
    "\n",
    "    dm = DataManager()\n",
    "    dm.read_data('data/train.csv', 'train', with_label=True)\n",
    "    dm.read_data('data/test.csv', 'test', with_label=False)\n",
    "    dm.read_data('data/users.csv', 'user', with_label=False, read_id=True)\n",
    "    dm.read_data('data/movies.csv', 'movie', with_label=False, read_id=True)\n",
    "    \n",
    "    dm.build_model_0()\n",
    "    dm.build_model_TA()\n",
    "    dm.build_model_TA_DNN()\n",
    "    dm.build_model_TA_no_bias()\n",
    "    if _model == 0:\n",
    "        model = dm.model_0\n",
    "    elif _model == 1:\n",
    "        model = dm.model_1\n",
    "    elif _model == 2:\n",
    "        model = dm.model_dnn\n",
    "    else:\n",
    "        model = dm.model_no_bias\n",
    "    adam = keras.optimizers.Adam(clipnorm=0.0001)\n",
    "    model.compile(optimizer=adam, loss={'output': 'mean_squared_error'}, metrics=['mean_squared_error'])\n",
    "    \n",
    "    filepath = 'model/model_1_1024.hdf5'\n",
    "    checkpoint1 = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    chechpoint2 = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='min')\n",
    "    \n",
    "    callbacks_list = [checkpoint1, chechpoint2]\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    history = model.fit({'user_input':dm.data['train'][0][:,0], 'movie_input':dm.data['train'][0][:,1]},\n",
    "              {'output':dm.data['train'][1][:,0]},\n",
    "             epochs=60,\n",
    "             batch_size=n_batch,\n",
    "             shuffle=True,\n",
    "             validation_split=0.05,\n",
    "             callbacks=callbacks_list,\n",
    "             verbose=1)\n",
    "    \n",
    "    dict_history = pd.DataFrame(history.history)\n",
    "    dict_history.to_csv('save/history_1024.csv')\n",
    "    \n",
    "    #model.save('model.hdf5')\n",
    "    \n",
    "    test_y = model.predict({'user_input':dm.data['test'][0][:,0], 'movie_input':dm.data['test'][0][:,1]},\n",
    "                          batch_size=n_batch, verbose=1)\n",
    "    # data normalization\n",
    "    #test_y = test_y * dm.train_rating_std + dm.train_rating_mean\n",
    "    np.save('test_y_1_1024.npy', test_y)\n",
    "    dm.write_file(test_y, './output_1_1024.csv')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user embedding shape: (6040, 1024)\n",
      "movie embedding shape: (6040, 1024)\n",
      "user embedding shape: (6040, 1024)\n",
      "movie embedding shape: (6040, 1024)\n",
      "user embedding shape: (6040, 1024)\n",
      "movie embedding shape: (6040, 1024)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "user_input (InputLayer)          (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "movie_input (InputLayer)         (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)          (None, 1, 1024)       6184960     user_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)          (None, 1, 1024)       6184960     movie_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 1024)          0           embedding_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)              (None, 1024)          0           embedding_6[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)          (None, 1, 1)          6040        user_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)          (None, 1, 1)          3883        movie_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dot_2 (Dot)                      (None, 1)             0           flatten_5[0][0]                  \n",
      "                                                                   flatten_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)              (None, 1)             0           embedding_7[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)              (None, 1)             0           embedding_8[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "output (Add)                     (None, 1)             0           dot_2[0][0]                      \n",
      "                                                                   flatten_7[0][0]                  \n",
      "                                                                   flatten_8[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 12,379,843\n",
      "Trainable params: 12,379,843\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 854879 samples, validate on 44994 samples\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[277,0] = 3948 is not in [0, 3883)\n\t [[Node: embedding_8/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_8/embeddings/read, embedding_8/Cast)]]\n\nCaused by op 'embedding_8/Gather', defined at:\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-0a902aad3aed>\", line 1, in <module>\n    main(1)\n  File \"<ipython-input-4-b75bc65399e6>\", line 30, in main\n    dm.build_model_TA()\n  File \"<ipython-input-2-42fee063c4de>\", line 68, in build_model_TA\n    item_bias = Embedding(n_items, 1, embeddings_initializer='zeros')(item_input)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/topology.py\", line 602, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/layers/embeddings.py\", line 134, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1134, in gather\n    return tf.gather(reference, indices)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1179, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): indices[277,0] = 3948 is not in [0, 3883)\n\t [[Node: embedding_8/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_8/embeddings/read, embedding_8/Cast)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[277,0] = 3948 is not in [0, 3883)\n\t [[Node: embedding_8/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_8/embeddings/read, embedding_8/Cast)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0a902aad3aed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-b75bc65399e6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(_model)\u001b[0m\n\u001b[1;32m     57\u001b[0m              \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m              \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m              verbose=1)\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mdict_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[277,0] = 3948 is not in [0, 3883)\n\t [[Node: embedding_8/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_8/embeddings/read, embedding_8/Cast)]]\n\nCaused by op 'embedding_8/Gather', defined at:\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-0a902aad3aed>\", line 1, in <module>\n    main(1)\n  File \"<ipython-input-4-b75bc65399e6>\", line 30, in main\n    dm.build_model_TA()\n  File \"<ipython-input-2-42fee063c4de>\", line 68, in build_model_TA\n    item_bias = Embedding(n_items, 1, embeddings_initializer='zeros')(item_input)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/topology.py\", line 602, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/layers/embeddings.py\", line 134, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1134, in gather\n    return tf.gather(reference, indices)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1179, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): indices[277,0] = 3948 is not in [0, 3883)\n\t [[Node: embedding_8/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_8/embeddings/read, embedding_8/Cast)]]\n"
     ]
    }
   ],
   "source": [
    "main(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user embedding shape: (6040, 1024)\n",
      "movie embedding shape: (6040, 1024)\n",
      "user embedding shape: (6040, 1024)\n",
      "movie embedding shape: (6040, 1024)\n",
      "user embedding shape: (6040, 1024)\n",
      "movie embedding shape: (6040, 1024)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "user_input (InputLayer)          (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "movie_input (InputLayer)         (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_41 (Embedding)         (None, 1, 1024)       6184960     user_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "embedding_42 (Embedding)         (None, 1, 1024)       6184960     movie_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_41 (Flatten)             (None, 1024)          0           embedding_41[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_42 (Flatten)             (None, 1024)          0           embedding_42[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "output (Dot)                     (None, 1)             0           flatten_41[0][0]                 \n",
      "                                                                   flatten_42[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 12,369,920\n",
      "Trainable params: 12,369,920\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 854879 samples, validate on 44994 samples\n",
      "Epoch 1/60\n",
      "847872/854879 [============================>.] - ETA: 0s - loss: 12.4807 - mean_squared_error: 12.4807Epoch 00000: val_loss improved from inf to 4.74901, saving model to model/model_1_1024_no_bias.hdf5\n",
      "854879/854879 [==============================] - 3s - loss: 12.4194 - mean_squared_error: 12.4194 - val_loss: 4.7490 - val_mean_squared_error: 4.7490\n",
      "Epoch 2/60\n",
      "847872/854879 [============================>.] - ETA: 0s - loss: 1.4435 - mean_squared_error: 1.4435Epoch 00001: val_loss improved from 4.74901 to 0.89622, saving model to model/model_1_1024_no_bias.hdf5\n",
      "854879/854879 [==============================] - 3s - loss: 1.4385 - mean_squared_error: 1.4385 - val_loss: 0.8962 - val_mean_squared_error: 0.8962\n",
      "Epoch 3/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.7012 - mean_squared_error: 0.7012Epoch 00002: val_loss improved from 0.89622 to 0.81787, saving model to model/model_1_1024_no_bias.hdf5\n",
      "854879/854879 [==============================] - 3s - loss: 0.7011 - mean_squared_error: 0.7011 - val_loss: 0.8179 - val_mean_squared_error: 0.8179\n",
      "Epoch 4/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.5182 - mean_squared_error: 0.5182Epoch 00003: val_loss improved from 0.81787 to 0.77943, saving model to model/model_1_1024_no_bias.hdf5\n",
      "854879/854879 [==============================] - 3s - loss: 0.5182 - mean_squared_error: 0.5182 - val_loss: 0.7794 - val_mean_squared_error: 0.7794\n",
      "Epoch 5/60\n",
      "841728/854879 [============================>.] - ETA: 0s - loss: 0.3423 - mean_squared_error: 0.3423Epoch 00004: val_loss improved from 0.77943 to 0.77239, saving model to model/model_1_1024_no_bias.hdf5\n",
      "854879/854879 [==============================] - 3s - loss: 0.3421 - mean_squared_error: 0.3421 - val_loss: 0.7724 - val_mean_squared_error: 0.7724\n",
      "Epoch 6/60\n",
      "849920/854879 [============================>.] - ETA: 0s - loss: 0.1906 - mean_squared_error: 0.1906Epoch 00005: val_loss did not improve\n",
      "854879/854879 [==============================] - 3s - loss: 0.1905 - mean_squared_error: 0.1905 - val_loss: 0.7858 - val_mean_squared_error: 0.7858\n",
      "Epoch 7/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.0892 - mean_squared_error: 0.0892Epoch 00006: val_loss did not improve\n",
      "854879/854879 [==============================] - 3s - loss: 0.0893 - mean_squared_error: 0.0893 - val_loss: 0.8100 - val_mean_squared_error: 0.8100\n",
      "Epoch 8/60\n",
      "847872/854879 [============================>.] - ETA: 0s - loss: 0.0382 - mean_squared_error: 0.0382Epoch 00007: val_loss did not improve\n",
      "854879/854879 [==============================] - 3s - loss: 0.0383 - mean_squared_error: 0.0383 - val_loss: 0.8255 - val_mean_squared_error: 0.8255\n",
      "Epoch 9/60\n",
      "847872/854879 [============================>.] - ETA: 0s - loss: 0.0192 - mean_squared_error: 0.0192Epoch 00008: val_loss did not improve\n",
      "854879/854879 [==============================] - 3s - loss: 0.0192 - mean_squared_error: 0.0192 - val_loss: 0.8341 - val_mean_squared_error: 0.8341\n",
      " 86016/100336 [========================>.....] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "main(3) # 1024, no bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user embedding shape: (6040, 1024)\n",
      "movie embedding shape: (6040, 1024)\n",
      "user embedding shape: (6040, 1024)\n",
      "movie embedding shape: (6040, 1024)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "user_input (InputLayer)          (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "movie_input (InputLayer)         (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_25 (Embedding)         (None, 1, 1024)       6184960     user_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "embedding_26 (Embedding)         (None, 1, 1024)       6184960     movie_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)             (None, 1024)          0           embedding_25[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_26 (Flatten)             (None, 1024)          0           embedding_26[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)         (None, 1, 1)          6040        user_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "embedding_28 (Embedding)         (None, 1, 1)          3883        movie_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dot_6 (Dot)                      (None, 1)             0           flatten_25[0][0]                 \n",
      "                                                                   flatten_26[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)             (None, 1)             0           embedding_27[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_28 (Flatten)             (None, 1)             0           embedding_28[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "output (Add)                     (None, 1)             0           dot_6[0][0]                      \n",
      "                                                                   flatten_27[0][0]                 \n",
      "                                                                   flatten_28[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 12,379,843\n",
      "Trainable params: 12,379,843\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 854879 samples, validate on 44994 samples\n",
      "Epoch 1/60\n",
      "841728/854879 [============================>.] - ETA: 0s - loss: 11.3191 - mean_squared_error: 11.3191Epoch 00000: val_loss improved from inf to 4.94592, saving model to model/model_1_1024_normal.hdf5\n",
      "854879/854879 [==============================] - 3s - loss: 11.2246 - mean_squared_error: 11.2246 - val_loss: 4.9459 - val_mean_squared_error: 4.9459\n",
      "Epoch 2/60\n",
      "843776/854879 [============================>.] - ETA: 0s - loss: 1.4826 - mean_squared_error: 1.4826Epoch 00001: val_loss improved from 4.94592 to 0.90786, saving model to model/model_1_1024_normal.hdf5\n",
      "854879/854879 [==============================] - 3s - loss: 1.4744 - mean_squared_error: 1.4744 - val_loss: 0.9079 - val_mean_squared_error: 0.9079\n",
      "Epoch 3/60\n",
      "843776/854879 [============================>.] - ETA: 0s - loss: 0.6919 - mean_squared_error: 0.6919Epoch 00002: val_loss improved from 0.90786 to 0.81891, saving model to model/model_1_1024_normal.hdf5\n",
      "854879/854879 [==============================] - 3s - loss: 0.6917 - mean_squared_error: 0.6917 - val_loss: 0.8189 - val_mean_squared_error: 0.8189\n",
      "Epoch 4/60\n",
      "841728/854879 [============================>.] - ETA: 0s - loss: 0.4951 - mean_squared_error: 0.4951Epoch 00003: val_loss improved from 0.81891 to 0.78032, saving model to model/model_1_1024_normal.hdf5\n",
      "854879/854879 [==============================] - 3s - loss: 0.4948 - mean_squared_error: 0.4948 - val_loss: 0.7803 - val_mean_squared_error: 0.7803\n",
      "Epoch 5/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.3129 - mean_squared_error: 0.3129Epoch 00004: val_loss did not improve\n",
      "854879/854879 [==============================] - 3s - loss: 0.3129 - mean_squared_error: 0.3129 - val_loss: 0.7804 - val_mean_squared_error: 0.7804\n",
      "Epoch 6/60\n",
      "841728/854879 [============================>.] - ETA: 0s - loss: 0.1645 - mean_squared_error: 0.1645Epoch 00005: val_loss did not improve\n",
      "854879/854879 [==============================] - 3s - loss: 0.1644 - mean_squared_error: 0.1644 - val_loss: 0.7956 - val_mean_squared_error: 0.7956\n",
      "Epoch 7/60\n",
      "847872/854879 [============================>.] - ETA: 0s - loss: 0.0753 - mean_squared_error: 0.0753Epoch 00006: val_loss did not improve\n",
      "854879/854879 [==============================] - 3s - loss: 0.0754 - mean_squared_error: 0.0754 - val_loss: 0.8291 - val_mean_squared_error: 0.8291\n",
      "Epoch 8/60\n",
      "841728/854879 [============================>.] - ETA: 0s - loss: 0.0320 - mean_squared_error: 0.0320Epoch 00007: val_loss did not improve\n",
      "854879/854879 [==============================] - 3s - loss: 0.0321 - mean_squared_error: 0.0321 - val_loss: 0.8350 - val_mean_squared_error: 0.8350\n",
      " 75776/100336 [=====================>........] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "main(1)# 1024, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user embedding shape: (6040, 8192)\n",
      "movie embedding shape: (6040, 8192)\n",
      "user embedding shape: (6040, 1024)\n",
      "movie embedding shape: (6040, 1024)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "user_input (InputLayer)          (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "movie_input (InputLayer)         (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_45 (Embedding)         (None, 1, 8192)       49479680    user_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "embedding_46 (Embedding)         (None, 1, 8192)       49479680    movie_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_45 (Flatten)             (None, 8192)          0           embedding_45[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_46 (Flatten)             (None, 8192)          0           embedding_46[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "embedding_47 (Embedding)         (None, 1, 1)          6040        user_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "embedding_48 (Embedding)         (None, 1, 1)          3883        movie_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dot_10 (Dot)                     (None, 1)             0           flatten_45[0][0]                 \n",
      "                                                                   flatten_46[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "flatten_47 (Flatten)             (None, 1)             0           embedding_47[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_48 (Flatten)             (None, 1)             0           embedding_48[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "output (Add)                     (None, 1)             0           dot_10[0][0]                     \n",
      "                                                                   flatten_47[0][0]                 \n",
      "                                                                   flatten_48[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 98,969,283\n",
      "Trainable params: 98,969,283\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 854879 samples, validate on 44994 samples\n",
      "Epoch 1/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 11.5155 - mean_squared_error: 11.5155Epoch 00000: val_loss improved from inf to 5.58740, saving model to model/model_1_8192.hdf5\n",
      "854879/854879 [==============================] - 20s - loss: 11.5095 - mean_squared_error: 11.5095 - val_loss: 5.5874 - val_mean_squared_error: 5.5874\n",
      "Epoch 2/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 1.4176 - mean_squared_error: 1.4176Epoch 00001: val_loss improved from 5.58740 to 1.06488, saving model to model/model_1_8192.hdf5\n",
      "854879/854879 [==============================] - 20s - loss: 1.4169 - mean_squared_error: 1.4169 - val_loss: 1.0649 - val_mean_squared_error: 1.0649\n",
      "Epoch 3/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.2589 - mean_squared_error: 0.2589Epoch 00002: val_loss did not improve\n",
      "854879/854879 [==============================] - 17s - loss: 0.2589 - mean_squared_error: 0.2589 - val_loss: 1.1398 - val_mean_squared_error: 1.1398\n",
      "Epoch 4/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.0355 - mean_squared_error: 0.0355Epoch 00003: val_loss did not improve\n",
      "854879/854879 [==============================] - 17s - loss: 0.0355 - mean_squared_error: 0.0355 - val_loss: 1.1231 - val_mean_squared_error: 1.1231\n",
      "Epoch 5/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.1866 - mean_squared_error: 0.1866Epoch 00004: val_loss did not improve\n",
      "854879/854879 [==============================] - 17s - loss: 0.1866 - mean_squared_error: 0.1866 - val_loss: 1.0929 - val_mean_squared_error: 1.0929\n",
      "Epoch 6/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.0601 - mean_squared_error: 0.0601Epoch 00005: val_loss did not improve\n",
      "854879/854879 [==============================] - 17s - loss: 0.0601 - mean_squared_error: 0.0601 - val_loss: 1.0829 - val_mean_squared_error: 1.0829\n",
      " 81920/100336 [=======================>......] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "main(1)#8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user embedding shape: (6040, 4)\n",
      "movie embedding shape: (6040, 4)\n",
      "user embedding shape: (6040, 1024)\n",
      "movie embedding shape: (6040, 1024)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "user_input (InputLayer)          (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "movie_input (InputLayer)         (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_153 (Embedding)        (None, 1, 4)          24160       user_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "embedding_154 (Embedding)        (None, 1, 4)          24160       movie_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_153 (Flatten)            (None, 4)             0           embedding_153[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "flatten_154 (Flatten)            (None, 4)             0           embedding_154[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "embedding_155 (Embedding)        (None, 1, 1)          6040        user_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "embedding_156 (Embedding)        (None, 1, 1)          3883        movie_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dot_34 (Dot)                     (None, 1)             0           flatten_153[0][0]                \n",
      "                                                                   flatten_154[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_155 (Flatten)            (None, 1)             0           embedding_155[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "flatten_156 (Flatten)            (None, 1)             0           embedding_156[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "output (Add)                     (None, 1)             0           dot_34[0][0]                     \n",
      "                                                                   flatten_155[0][0]                \n",
      "                                                                   flatten_156[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 58,243\n",
      "Trainable params: 58,243\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 854879 samples, validate on 44994 samples\n",
      "Epoch 1/60\n",
      "849920/854879 [============================>.] - ETA: 0s - loss: 12.3111 - mean_squared_error: 12.3111Epoch 00000: val_loss improved from inf to 10.55211, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 11s - loss: 12.3005 - mean_squared_error: 12.3005 - val_loss: 10.5521 - val_mean_squared_error: 10.5521\n",
      "Epoch 2/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 7.8414 - mean_squared_error: 7.8414Epoch 00001: val_loss improved from 10.55211 to 4.50589, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 7.8298 - mean_squared_error: 7.8298 - val_loss: 4.5059 - val_mean_squared_error: 4.5059\n",
      "Epoch 3/60\n",
      "849920/854879 [============================>.] - ETA: 0s - loss: 2.4943 - mean_squared_error: 2.4943Epoch 00002: val_loss improved from 4.50589 to 1.47803, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 2.4885 - mean_squared_error: 2.4885 - val_loss: 1.4780 - val_mean_squared_error: 1.4780\n",
      "Epoch 4/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 1.2006 - mean_squared_error: 1.2006Epoch 00003: val_loss improved from 1.47803 to 1.06180, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 1.2005 - mean_squared_error: 1.2005 - val_loss: 1.0618 - val_mean_squared_error: 1.0618\n",
      "Epoch 5/60\n",
      "849920/854879 [============================>.] - ETA: 0s - loss: 0.9721 - mean_squared_error: 0.9721Epoch 00004: val_loss improved from 1.06180 to 0.94086, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.9719 - mean_squared_error: 0.9719 - val_loss: 0.9409 - val_mean_squared_error: 0.9409\n",
      "Epoch 6/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.8944 - mean_squared_error: 0.8944Epoch 00005: val_loss improved from 0.94086 to 0.89208, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.8944 - mean_squared_error: 0.8944 - val_loss: 0.8921 - val_mean_squared_error: 0.8921\n",
      "Epoch 7/60\n",
      "849920/854879 [============================>.] - ETA: 0s - loss: 0.8603 - mean_squared_error: 0.8603Epoch 00006: val_loss improved from 0.89208 to 0.86796, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.8602 - mean_squared_error: 0.8602 - val_loss: 0.8680 - val_mean_squared_error: 0.8680\n",
      "Epoch 8/60\n",
      "849920/854879 [============================>.] - ETA: 0s - loss: 0.8430 - mean_squared_error: 0.8430Epoch 00007: val_loss improved from 0.86796 to 0.85493, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.8430 - mean_squared_error: 0.8430 - val_loss: 0.8549 - val_mean_squared_error: 0.8549\n",
      "Epoch 9/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.8333 - mean_squared_error: 0.8333Epoch 00008: val_loss improved from 0.85493 to 0.84721, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.8332 - mean_squared_error: 0.8332 - val_loss: 0.8472 - val_mean_squared_error: 0.8472\n",
      "Epoch 10/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.8272 - mean_squared_error: 0.8272Epoch 00009: val_loss improved from 0.84721 to 0.84276, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.8272 - mean_squared_error: 0.8272 - val_loss: 0.8428 - val_mean_squared_error: 0.8428\n",
      "Epoch 11/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.8232 - mean_squared_error: 0.8232Epoch 00010: val_loss improved from 0.84276 to 0.83925, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.8233 - mean_squared_error: 0.8233 - val_loss: 0.8392 - val_mean_squared_error: 0.8392\n",
      "Epoch 12/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.8205 - mean_squared_error: 0.8205Epoch 00011: val_loss improved from 0.83925 to 0.83735, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.8205 - mean_squared_error: 0.8205 - val_loss: 0.8374 - val_mean_squared_error: 0.8374\n",
      "Epoch 13/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.8183 - mean_squared_error: 0.8183Epoch 00012: val_loss improved from 0.83735 to 0.83562, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.8183 - mean_squared_error: 0.8183 - val_loss: 0.8356 - val_mean_squared_error: 0.8356\n",
      "Epoch 14/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.8166 - mean_squared_error: 0.8166Epoch 00013: val_loss improved from 0.83562 to 0.83411, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.8165 - mean_squared_error: 0.8165 - val_loss: 0.8341 - val_mean_squared_error: 0.8341\n",
      "Epoch 15/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.8151 - mean_squared_error: 0.8151Epoch 00014: val_loss improved from 0.83411 to 0.83247, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.8151 - mean_squared_error: 0.8151 - val_loss: 0.8325 - val_mean_squared_error: 0.8325\n",
      "Epoch 16/60\n",
      "849920/854879 [============================>.] - ETA: 0s - loss: 0.8138 - mean_squared_error: 0.8138Epoch 00015: val_loss improved from 0.83247 to 0.83162, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.8137 - mean_squared_error: 0.8137 - val_loss: 0.8316 - val_mean_squared_error: 0.8316\n",
      "Epoch 17/60\n",
      "849920/854879 [============================>.] - ETA: 0s - loss: 0.8124 - mean_squared_error: 0.8124Epoch 00016: val_loss improved from 0.83162 to 0.83035, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.8124 - mean_squared_error: 0.8124 - val_loss: 0.8303 - val_mean_squared_error: 0.8303\n",
      "Epoch 18/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.8113 - mean_squared_error: 0.8113Epoch 00017: val_loss improved from 0.83035 to 0.82971, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.8113 - mean_squared_error: 0.8113 - val_loss: 0.8297 - val_mean_squared_error: 0.8297\n",
      "Epoch 19/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.8101 - mean_squared_error: 0.8101Epoch 00018: val_loss improved from 0.82971 to 0.82872, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.8102 - mean_squared_error: 0.8102 - val_loss: 0.8287 - val_mean_squared_error: 0.8287\n",
      "Epoch 20/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.8090 - mean_squared_error: 0.8090Epoch 00019: val_loss improved from 0.82872 to 0.82798, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.8089 - mean_squared_error: 0.8089 - val_loss: 0.8280 - val_mean_squared_error: 0.8280\n",
      "Epoch 21/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.8079 - mean_squared_error: 0.8079Epoch 00020: val_loss improved from 0.82798 to 0.82695, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.8079 - mean_squared_error: 0.8079 - val_loss: 0.8270 - val_mean_squared_error: 0.8270\n",
      "Epoch 22/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.8066 - mean_squared_error: 0.8066Epoch 00021: val_loss improved from 0.82695 to 0.82628, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.8067 - mean_squared_error: 0.8067 - val_loss: 0.8263 - val_mean_squared_error: 0.8263\n",
      "Epoch 23/60\n",
      "849920/854879 [============================>.] - ETA: 0s - loss: 0.8055 - mean_squared_error: 0.8055Epoch 00022: val_loss improved from 0.82628 to 0.82583, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.8055 - mean_squared_error: 0.8055 - val_loss: 0.8258 - val_mean_squared_error: 0.8258\n",
      "Epoch 24/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.8040 - mean_squared_error: 0.8040Epoch 00023: val_loss improved from 0.82583 to 0.82462, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.8041 - mean_squared_error: 0.8041 - val_loss: 0.8246 - val_mean_squared_error: 0.8246\n",
      "Epoch 25/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.8024 - mean_squared_error: 0.8024Epoch 00024: val_loss improved from 0.82462 to 0.82348, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.8026 - mean_squared_error: 0.8026 - val_loss: 0.8235 - val_mean_squared_error: 0.8235\n",
      "Epoch 26/60\n",
      "849920/854879 [============================>.] - ETA: 0s - loss: 0.8012 - mean_squared_error: 0.8012Epoch 00025: val_loss improved from 0.82348 to 0.82210, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.8011 - mean_squared_error: 0.8011 - val_loss: 0.8221 - val_mean_squared_error: 0.8221\n",
      "Epoch 27/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.7994 - mean_squared_error: 0.7994Epoch 00026: val_loss improved from 0.82210 to 0.82050, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7994 - mean_squared_error: 0.7994 - val_loss: 0.8205 - val_mean_squared_error: 0.8205\n",
      "Epoch 28/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.7975 - mean_squared_error: 0.7975Epoch 00027: val_loss improved from 0.82050 to 0.81942, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7976 - mean_squared_error: 0.7976 - val_loss: 0.8194 - val_mean_squared_error: 0.8194\n",
      "Epoch 29/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.7955 - mean_squared_error: 0.7955Epoch 00028: val_loss improved from 0.81942 to 0.81756, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7955 - mean_squared_error: 0.7955 - val_loss: 0.8176 - val_mean_squared_error: 0.8176\n",
      "Epoch 30/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.7930 - mean_squared_error: 0.7930Epoch 00029: val_loss improved from 0.81756 to 0.81574, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7932 - mean_squared_error: 0.7932 - val_loss: 0.8157 - val_mean_squared_error: 0.8157\n",
      "Epoch 31/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.7907 - mean_squared_error: 0.7907Epoch 00030: val_loss improved from 0.81574 to 0.81389, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7907 - mean_squared_error: 0.7907 - val_loss: 0.8139 - val_mean_squared_error: 0.8139\n",
      "Epoch 32/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.7879 - mean_squared_error: 0.7879Epoch 00031: val_loss improved from 0.81389 to 0.81180, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7879 - mean_squared_error: 0.7879 - val_loss: 0.8118 - val_mean_squared_error: 0.8118\n",
      "Epoch 33/60\n",
      "849920/854879 [============================>.] - ETA: 0s - loss: 0.7850 - mean_squared_error: 0.7850Epoch 00032: val_loss improved from 0.81180 to 0.80951, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7850 - mean_squared_error: 0.7850 - val_loss: 0.8095 - val_mean_squared_error: 0.8095\n",
      "Epoch 34/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.7819 - mean_squared_error: 0.7819Epoch 00033: val_loss improved from 0.80951 to 0.80702, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7818 - mean_squared_error: 0.7818 - val_loss: 0.8070 - val_mean_squared_error: 0.8070\n",
      "Epoch 35/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.7784 - mean_squared_error: 0.7784Epoch 00034: val_loss improved from 0.80702 to 0.80442, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7784 - mean_squared_error: 0.7784 - val_loss: 0.8044 - val_mean_squared_error: 0.8044\n",
      "Epoch 36/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.7749 - mean_squared_error: 0.7749Epoch 00035: val_loss improved from 0.80442 to 0.80179, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7748 - mean_squared_error: 0.7748 - val_loss: 0.8018 - val_mean_squared_error: 0.8018\n",
      "Epoch 37/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.7712 - mean_squared_error: 0.7712Epoch 00036: val_loss improved from 0.80179 to 0.79916, saving model to model/model_1_4.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "854879/854879 [==============================] - 10s - loss: 0.7712 - mean_squared_error: 0.7712 - val_loss: 0.7992 - val_mean_squared_error: 0.7992\n",
      "Epoch 38/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.7675 - mean_squared_error: 0.7675Epoch 00037: val_loss improved from 0.79916 to 0.79647, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7675 - mean_squared_error: 0.7675 - val_loss: 0.7965 - val_mean_squared_error: 0.7965\n",
      "Epoch 39/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.7637 - mean_squared_error: 0.7637Epoch 00038: val_loss improved from 0.79647 to 0.79412, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7638 - mean_squared_error: 0.7638 - val_loss: 0.7941 - val_mean_squared_error: 0.7941\n",
      "Epoch 40/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.7601 - mean_squared_error: 0.7601Epoch 00039: val_loss improved from 0.79412 to 0.79178, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7602 - mean_squared_error: 0.7602 - val_loss: 0.7918 - val_mean_squared_error: 0.7918\n",
      "Epoch 41/60\n",
      "849920/854879 [============================>.] - ETA: 0s - loss: 0.7567 - mean_squared_error: 0.7567Epoch 00040: val_loss improved from 0.79178 to 0.78985, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7567 - mean_squared_error: 0.7567 - val_loss: 0.7899 - val_mean_squared_error: 0.7899\n",
      "Epoch 42/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.7533 - mean_squared_error: 0.7533Epoch 00041: val_loss improved from 0.78985 to 0.78722, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7533 - mean_squared_error: 0.7533 - val_loss: 0.7872 - val_mean_squared_error: 0.7872\n",
      "Epoch 43/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.7500 - mean_squared_error: 0.7500Epoch 00042: val_loss improved from 0.78722 to 0.78516, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7501 - mean_squared_error: 0.7501 - val_loss: 0.7852 - val_mean_squared_error: 0.7852\n",
      "Epoch 44/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.7471 - mean_squared_error: 0.7471Epoch 00043: val_loss improved from 0.78516 to 0.78363, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7470 - mean_squared_error: 0.7470 - val_loss: 0.7836 - val_mean_squared_error: 0.7836\n",
      "Epoch 45/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.7441 - mean_squared_error: 0.7441Epoch 00044: val_loss improved from 0.78363 to 0.78173, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7441 - mean_squared_error: 0.7441 - val_loss: 0.7817 - val_mean_squared_error: 0.7817\n",
      "Epoch 46/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.7414 - mean_squared_error: 0.7414Epoch 00045: val_loss improved from 0.78173 to 0.78022, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7414 - mean_squared_error: 0.7414 - val_loss: 0.7802 - val_mean_squared_error: 0.7802\n",
      "Epoch 47/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.7387 - mean_squared_error: 0.7387Epoch 00046: val_loss improved from 0.78022 to 0.77921, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7388 - mean_squared_error: 0.7388 - val_loss: 0.7792 - val_mean_squared_error: 0.7792\n",
      "Epoch 48/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.7363 - mean_squared_error: 0.7363Epoch 00047: val_loss improved from 0.77921 to 0.77762, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7363 - mean_squared_error: 0.7363 - val_loss: 0.7776 - val_mean_squared_error: 0.7776\n",
      "Epoch 49/60\n",
      "849920/854879 [============================>.] - ETA: 0s - loss: 0.7339 - mean_squared_error: 0.7339Epoch 00048: val_loss improved from 0.77762 to 0.77611, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7340 - mean_squared_error: 0.7340 - val_loss: 0.7761 - val_mean_squared_error: 0.7761\n",
      "Epoch 50/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.7318 - mean_squared_error: 0.7318Epoch 00049: val_loss improved from 0.77611 to 0.77488, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7319 - mean_squared_error: 0.7319 - val_loss: 0.7749 - val_mean_squared_error: 0.7749\n",
      "Epoch 51/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.7296 - mean_squared_error: 0.7296Epoch 00050: val_loss improved from 0.77488 to 0.77438, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7297 - mean_squared_error: 0.7297 - val_loss: 0.7744 - val_mean_squared_error: 0.7744\n",
      "Epoch 52/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.7279 - mean_squared_error: 0.7279Epoch 00051: val_loss improved from 0.77438 to 0.77382, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7279 - mean_squared_error: 0.7279 - val_loss: 0.7738 - val_mean_squared_error: 0.7738\n",
      "Epoch 53/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.7259 - mean_squared_error: 0.7259Epoch 00052: val_loss improved from 0.77382 to 0.77248, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7260 - mean_squared_error: 0.7260 - val_loss: 0.7725 - val_mean_squared_error: 0.7725\n",
      "Epoch 54/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.7243 - mean_squared_error: 0.7243Epoch 00053: val_loss improved from 0.77248 to 0.77182, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7242 - mean_squared_error: 0.7242 - val_loss: 0.7718 - val_mean_squared_error: 0.7718\n",
      "Epoch 55/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.7225 - mean_squared_error: 0.7225Epoch 00054: val_loss improved from 0.77182 to 0.77112, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7226 - mean_squared_error: 0.7226 - val_loss: 0.7711 - val_mean_squared_error: 0.7711\n",
      "Epoch 56/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.7210 - mean_squared_error: 0.7210Epoch 00055: val_loss improved from 0.77112 to 0.77038, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7210 - mean_squared_error: 0.7210 - val_loss: 0.7704 - val_mean_squared_error: 0.7704\n",
      "Epoch 57/60\n",
      "849920/854879 [============================>.] - ETA: 0s - loss: 0.7193 - mean_squared_error: 0.7193Epoch 00056: val_loss improved from 0.77038 to 0.76975, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7194 - mean_squared_error: 0.7194 - val_loss: 0.7698 - val_mean_squared_error: 0.7698\n",
      "Epoch 58/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.7180 - mean_squared_error: 0.7180Epoch 00057: val_loss improved from 0.76975 to 0.76934, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7180 - mean_squared_error: 0.7180 - val_loss: 0.7693 - val_mean_squared_error: 0.7693\n",
      "Epoch 59/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.7165 - mean_squared_error: 0.7165Epoch 00058: val_loss improved from 0.76934 to 0.76896, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7165 - mean_squared_error: 0.7165 - val_loss: 0.7690 - val_mean_squared_error: 0.7690\n",
      "Epoch 60/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.7152 - mean_squared_error: 0.7152Epoch 00059: val_loss improved from 0.76896 to 0.76832, saving model to model/model_1_4.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7152 - mean_squared_error: 0.7152 - val_loss: 0.7683 - val_mean_squared_error: 0.7683\n",
      " 96256/100336 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "main(1)#4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user embedding shape: (6040, 32)\n",
      "movie embedding shape: (6040, 32)\n",
      "user embedding shape: (6040, 1024)\n",
      "movie embedding shape: (6040, 1024)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "user_input (InputLayer)          (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "movie_input (InputLayer)         (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_143 (Embedding)        (None, 1, 32)         193280      user_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "embedding_144 (Embedding)        (None, 1, 32)         193280      movie_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_143 (Flatten)            (None, 32)            0           embedding_143[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "flatten_144 (Flatten)            (None, 32)            0           embedding_144[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "embedding_145 (Embedding)        (None, 1, 1)          6040        user_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "embedding_146 (Embedding)        (None, 1, 1)          3883        movie_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dot_32 (Dot)                     (None, 1)             0           flatten_143[0][0]                \n",
      "                                                                   flatten_144[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_145 (Flatten)            (None, 1)             0           embedding_145[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "flatten_146 (Flatten)            (None, 1)             0           embedding_146[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "output (Add)                     (None, 1)             0           dot_32[0][0]                     \n",
      "                                                                   flatten_145[0][0]                \n",
      "                                                                   flatten_146[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 396,483\n",
      "Trainable params: 396,483\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 854879 samples, validate on 44994 samples\n",
      "Epoch 1/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 12.2186 - mean_squared_error: 12.2186Epoch 00000: val_loss improved from inf to 9.82847, saving model to model/model_1_32.hdf5\n",
      "854879/854879 [==============================] - 11s - loss: 12.2103 - mean_squared_error: 12.2103 - val_loss: 9.8285 - val_mean_squared_error: 9.8285\n",
      "Epoch 2/60\n",
      "849920/854879 [============================>.] - ETA: 0s - loss: 4.3417 - mean_squared_error: 4.3417Epoch 00001: val_loss improved from 9.82847 to 1.31566, saving model to model/model_1_32.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 4.3241 - mean_squared_error: 4.3241 - val_loss: 1.3157 - val_mean_squared_error: 1.3157\n",
      "Epoch 3/60\n",
      "849920/854879 [============================>.] - ETA: 0s - loss: 1.0298 - mean_squared_error: 1.0298Epoch 00002: val_loss improved from 1.31566 to 0.90539, saving model to model/model_1_32.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 1.0290 - mean_squared_error: 1.0290 - val_loss: 0.9054 - val_mean_squared_error: 0.9054\n",
      "Epoch 4/60\n",
      "849920/854879 [============================>.] - ETA: 0s - loss: 0.8640 - mean_squared_error: 0.8640Epoch 00003: val_loss improved from 0.90539 to 0.84907, saving model to model/model_1_32.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.8638 - mean_squared_error: 0.8638 - val_loss: 0.8491 - val_mean_squared_error: 0.8491\n",
      "Epoch 5/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.8230 - mean_squared_error: 0.8230Epoch 00004: val_loss improved from 0.84907 to 0.82395, saving model to model/model_1_32.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.8230 - mean_squared_error: 0.8230 - val_loss: 0.8240 - val_mean_squared_error: 0.8240\n",
      "Epoch 6/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.7968 - mean_squared_error: 0.7968Epoch 00005: val_loss improved from 0.82395 to 0.80747, saving model to model/model_1_32.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7968 - mean_squared_error: 0.7968 - val_loss: 0.8075 - val_mean_squared_error: 0.8075\n",
      "Epoch 7/60\n",
      "849920/854879 [============================>.] - ETA: 0s - loss: 0.7756 - mean_squared_error: 0.7756Epoch 00006: val_loss improved from 0.80747 to 0.79427, saving model to model/model_1_32.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7755 - mean_squared_error: 0.7755 - val_loss: 0.7943 - val_mean_squared_error: 0.7943\n",
      "Epoch 8/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.7569 - mean_squared_error: 0.7569Epoch 00007: val_loss improved from 0.79427 to 0.78279, saving model to model/model_1_32.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7569 - mean_squared_error: 0.7569 - val_loss: 0.7828 - val_mean_squared_error: 0.7828\n",
      "Epoch 9/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.7398 - mean_squared_error: 0.7398Epoch 00008: val_loss improved from 0.78279 to 0.77278, saving model to model/model_1_32.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7398 - mean_squared_error: 0.7398 - val_loss: 0.7728 - val_mean_squared_error: 0.7728\n",
      "Epoch 10/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.7233 - mean_squared_error: 0.7233Epoch 00009: val_loss improved from 0.77278 to 0.76512, saving model to model/model_1_32.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7234 - mean_squared_error: 0.7234 - val_loss: 0.7651 - val_mean_squared_error: 0.7651\n",
      "Epoch 11/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.7076 - mean_squared_error: 0.7076Epoch 00010: val_loss improved from 0.76512 to 0.75826, saving model to model/model_1_32.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.7076 - mean_squared_error: 0.7076 - val_loss: 0.7583 - val_mean_squared_error: 0.7583\n",
      "Epoch 12/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.6926 - mean_squared_error: 0.6926Epoch 00011: val_loss improved from 0.75826 to 0.75181, saving model to model/model_1_32.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.6925 - mean_squared_error: 0.6925 - val_loss: 0.7518 - val_mean_squared_error: 0.7518\n",
      "Epoch 13/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.6785 - mean_squared_error: 0.6785Epoch 00012: val_loss improved from 0.75181 to 0.74855, saving model to model/model_1_32.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.6785 - mean_squared_error: 0.6785 - val_loss: 0.7486 - val_mean_squared_error: 0.7486\n",
      "Epoch 14/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.6653 - mean_squared_error: 0.6653Epoch 00013: val_loss improved from 0.74855 to 0.74465, saving model to model/model_1_32.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "854879/854879 [==============================] - 10s - loss: 0.6653 - mean_squared_error: 0.6653 - val_loss: 0.7446 - val_mean_squared_error: 0.7446\n",
      "Epoch 15/60\n",
      "849920/854879 [============================>.] - ETA: 0s - loss: 0.6528 - mean_squared_error: 0.6528Epoch 00014: val_loss improved from 0.74465 to 0.74091, saving model to model/model_1_32.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.6529 - mean_squared_error: 0.6529 - val_loss: 0.7409 - val_mean_squared_error: 0.7409\n",
      "Epoch 16/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.6409 - mean_squared_error: 0.6409Epoch 00015: val_loss improved from 0.74091 to 0.74015, saving model to model/model_1_32.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.6410 - mean_squared_error: 0.6410 - val_loss: 0.7401 - val_mean_squared_error: 0.7401\n",
      "Epoch 17/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.6296 - mean_squared_error: 0.6296Epoch 00016: val_loss improved from 0.74015 to 0.73832, saving model to model/model_1_32.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.6296 - mean_squared_error: 0.6296 - val_loss: 0.7383 - val_mean_squared_error: 0.7383\n",
      "Epoch 18/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.6183 - mean_squared_error: 0.6183Epoch 00017: val_loss improved from 0.73832 to 0.73816, saving model to model/model_1_32.hdf5\n",
      "854879/854879 [==============================] - 10s - loss: 0.6184 - mean_squared_error: 0.6184 - val_loss: 0.7382 - val_mean_squared_error: 0.7382\n",
      "Epoch 19/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.6076 - mean_squared_error: 0.6076Epoch 00018: val_loss did not improve\n",
      "854879/854879 [==============================] - 10s - loss: 0.6075 - mean_squared_error: 0.6075 - val_loss: 0.7382 - val_mean_squared_error: 0.7382\n",
      "Epoch 20/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.5969 - mean_squared_error: 0.5969Epoch 00019: val_loss did not improve\n",
      "854879/854879 [==============================] - 10s - loss: 0.5969 - mean_squared_error: 0.5969 - val_loss: 0.7392 - val_mean_squared_error: 0.7392\n",
      "Epoch 21/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.5865 - mean_squared_error: 0.5865Epoch 00020: val_loss did not improve\n",
      "854879/854879 [==============================] - 10s - loss: 0.5864 - mean_squared_error: 0.5864 - val_loss: 0.7402 - val_mean_squared_error: 0.7402\n",
      "Epoch 22/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.5764 - mean_squared_error: 0.5764Epoch 00021: val_loss did not improve\n",
      "854879/854879 [==============================] - 10s - loss: 0.5764 - mean_squared_error: 0.5764 - val_loss: 0.7415 - val_mean_squared_error: 0.7415\n",
      " 96256/100336 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "main(1)#32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user embedding shape: (6040, 1024)\n",
      "movie embedding shape: (6040, 1024)\n",
      "user embedding shape: (6040, 1024)\n",
      "movie embedding shape: (6040, 1024)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "user_input (InputLayer)          (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "movie_input (InputLayer)         (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_113 (Embedding)        (None, 1, 1024)       6184960     user_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "embedding_114 (Embedding)        (None, 1, 1024)       6184960     movie_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_113 (Flatten)            (None, 1024)          0           embedding_113[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "flatten_114 (Flatten)            (None, 1024)          0           embedding_114[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "embedding_115 (Embedding)        (None, 1, 1)          6040        user_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "embedding_116 (Embedding)        (None, 1, 1)          3883        movie_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dot_26 (Dot)                     (None, 1)             0           flatten_113[0][0]                \n",
      "                                                                   flatten_114[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_115 (Flatten)            (None, 1)             0           embedding_115[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "flatten_116 (Flatten)            (None, 1)             0           embedding_116[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "output (Add)                     (None, 1)             0           dot_26[0][0]                     \n",
      "                                                                   flatten_115[0][0]                \n",
      "                                                                   flatten_116[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 12,379,843\n",
      "Trainable params: 12,379,843\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 854879 samples, validate on 44994 samples\n",
      "Epoch 1/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 11.5051 - mean_squared_error: 11.5051Epoch 00000: val_loss improved from inf to 5.24808, saving model to model/model_1_1024.hdf5\n",
      "854879/854879 [==============================] - 14s - loss: 11.4842 - mean_squared_error: 11.4842 - val_loss: 5.2481 - val_mean_squared_error: 5.2481\n",
      "Epoch 2/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 1.5198 - mean_squared_error: 1.5198Epoch 00001: val_loss improved from 5.24808 to 0.88630, saving model to model/model_1_1024.hdf5\n",
      "854879/854879 [==============================] - 13s - loss: 1.5175 - mean_squared_error: 1.5175 - val_loss: 0.8863 - val_mean_squared_error: 0.8863\n",
      "Epoch 3/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.6867 - mean_squared_error: 0.6867Epoch 00002: val_loss improved from 0.88630 to 0.80462, saving model to model/model_1_1024.hdf5\n",
      "854879/854879 [==============================] - 13s - loss: 0.6867 - mean_squared_error: 0.6867 - val_loss: 0.8046 - val_mean_squared_error: 0.8046\n",
      "Epoch 4/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.4930 - mean_squared_error: 0.4930Epoch 00003: val_loss improved from 0.80462 to 0.77250, saving model to model/model_1_1024.hdf5\n",
      "854879/854879 [==============================] - 13s - loss: 0.4930 - mean_squared_error: 0.4930 - val_loss: 0.7725 - val_mean_squared_error: 0.7725\n",
      "Epoch 5/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.3117 - mean_squared_error: 0.3117Epoch 00004: val_loss improved from 0.77250 to 0.77172, saving model to model/model_1_1024.hdf5\n",
      "854879/854879 [==============================] - 13s - loss: 0.3116 - mean_squared_error: 0.3116 - val_loss: 0.7717 - val_mean_squared_error: 0.7717\n",
      "Epoch 6/60\n",
      "851968/854879 [============================>.] - ETA: 0s - loss: 0.1634 - mean_squared_error: 0.1634Epoch 00005: val_loss did not improve\n",
      "854879/854879 [==============================] - 13s - loss: 0.1634 - mean_squared_error: 0.1634 - val_loss: 0.7887 - val_mean_squared_error: 0.7887\n",
      "Epoch 7/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.0716 - mean_squared_error: 0.0716Epoch 00006: val_loss did not improve\n",
      "854879/854879 [==============================] - 13s - loss: 0.0716 - mean_squared_error: 0.0716 - val_loss: 0.8136 - val_mean_squared_error: 0.8136\n",
      "Epoch 8/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.0292 - mean_squared_error: 0.0292Epoch 00007: val_loss did not improve\n",
      "854879/854879 [==============================] - 13s - loss: 0.0292 - mean_squared_error: 0.0292 - val_loss: 0.8269 - val_mean_squared_error: 0.8269\n",
      "Epoch 9/60\n",
      "854016/854879 [============================>.] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0165Epoch 00008: val_loss did not improve\n",
      "854879/854879 [==============================] - 12s - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.8313 - val_mean_squared_error: 0.8313\n",
      " 94208/100336 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "main(1)#1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user embedding shape: (6040, 6666)\n",
      "movie embedding shape: (6040, 6666)\n",
      "user embedding shape: (6040, 6666)\n",
      "movie embedding shape: (6040, 6666)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "user_input (InputLayer)          (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "movie_input (InputLayer)         (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_77 (Embedding)         (None, 1, 6666)       40262640    user_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "embedding_78 (Embedding)         (None, 1, 6666)       40262640    movie_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_77 (Flatten)             (None, 6666)          0           embedding_77[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_78 (Flatten)             (None, 6666)          0           embedding_78[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 13332)         0           flatten_77[0][0]                 \n",
      "                                                                   flatten_78[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 128)           1706624     concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 64)            8256        dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "output (Dense)                   (None, 1)             65          dense_5[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 82,240,225\n",
      "Trainable params: 82,240,225\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 809885 samples, validate on 89988 samples\n",
      "Epoch 1/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 1.8481 - mean_squared_error: 1.8481Epoch 00000: val_loss improved from inf to 0.86286, saving model to model/model_0.hdf5\n",
      "809885/809885 [==============================] - 47s - loss: 1.8470 - mean_squared_error: 1.8470 - val_loss: 0.8629 - val_mean_squared_error: 0.8629\n",
      "Epoch 2/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.8254 - mean_squared_error: 0.8254Epoch 00001: val_loss improved from 0.86286 to 0.83233, saving model to model/model_0.hdf5\n",
      "809885/809885 [==============================] - 45s - loss: 0.8254 - mean_squared_error: 0.8254 - val_loss: 0.8323 - val_mean_squared_error: 0.8323\n",
      "Epoch 3/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.7825 - mean_squared_error: 0.7825Epoch 00002: val_loss improved from 0.83233 to 0.80557, saving model to model/model_0.hdf5\n",
      "809885/809885 [==============================] - 45s - loss: 0.7825 - mean_squared_error: 0.7825 - val_loss: 0.8056 - val_mean_squared_error: 0.8056\n",
      "Epoch 4/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.7476 - mean_squared_error: 0.7476Epoch 00003: val_loss improved from 0.80557 to 0.79173, saving model to model/model_0.hdf5\n",
      "809885/809885 [==============================] - 45s - loss: 0.7475 - mean_squared_error: 0.7475 - val_loss: 0.7917 - val_mean_squared_error: 0.7917\n",
      "Epoch 5/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.7061 - mean_squared_error: 0.7061Epoch 00004: val_loss improved from 0.79173 to 0.79045, saving model to model/model_0.hdf5\n",
      "809885/809885 [==============================] - 45s - loss: 0.7062 - mean_squared_error: 0.7062 - val_loss: 0.7905 - val_mean_squared_error: 0.7905\n",
      "Epoch 6/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.6541 - mean_squared_error: 0.6541Epoch 00005: val_loss did not improve\n",
      "809885/809885 [==============================] - 42s - loss: 0.6541 - mean_squared_error: 0.6541 - val_loss: 0.7959 - val_mean_squared_error: 0.7959\n",
      "Epoch 7/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.6019 - mean_squared_error: 0.6019Epoch 00006: val_loss did not improve\n",
      "809885/809885 [==============================] - 42s - loss: 0.6020 - mean_squared_error: 0.6020 - val_loss: 0.8075 - val_mean_squared_error: 0.8075\n",
      "Epoch 8/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.5519 - mean_squared_error: 0.5519Epoch 00007: val_loss did not improve\n",
      "809885/809885 [==============================] - 42s - loss: 0.5520 - mean_squared_error: 0.5520 - val_loss: 0.8237 - val_mean_squared_error: 0.8237\n",
      "Epoch 9/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.4975 - mean_squared_error: 0.4975Epoch 00008: val_loss did not improve\n",
      "809885/809885 [==============================] - 42s - loss: 0.4976 - mean_squared_error: 0.4976 - val_loss: 0.8430 - val_mean_squared_error: 0.8430\n",
      " 92160/100336 [==========================>...] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "main(2) # dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user embedding shape: (6040, 6666)\n",
      "movie embedding shape: (6040, 6666)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "user_input (InputLayer)          (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "movie_input (InputLayer)         (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_35 (Embedding)         (None, 1, 128)        505856      movie_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "embedding_33 (Embedding)         (None, 1, 128)        773120      user_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "embedding_34 (Embedding)         (None, 1, 1)          6040        user_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "embedding_36 (Embedding)         (None, 1, 1)          3952        movie_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)             (None, 128)           0           embedding_35[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)             (None, 128)           0           embedding_33[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)             (None, 1)             0           embedding_34[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_36 (Flatten)             (None, 1)             0           embedding_36[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dot_9 (Dot)                      (None, 1)             0           flatten_35[0][0]                 \n",
      "                                                                   flatten_33[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "output (Add)                     (None, 1)             0           flatten_34[0][0]                 \n",
      "                                                                   flatten_36[0][0]                 \n",
      "                                                                   dot_9[0][0]                      \n",
      "====================================================================================================\n",
      "Total params: 1,288,968\n",
      "Trainable params: 1,288,968\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 809885 samples, validate on 89988 samples\n",
      "Epoch 1/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 11.9310 - mean_squared_error: 11.9310Epoch 00000: val_loss improved from inf to 6.96271, saving model to model/model_0.hdf5\n",
      "809885/809885 [==============================] - 10s - loss: 11.9254 - mean_squared_error: 11.9254 - val_loss: 6.9627 - val_mean_squared_error: 6.9627\n",
      "Epoch 2/60\n",
      "806912/809885 [============================>.] - ETA: 0s - loss: 2.1149 - mean_squared_error: 2.1149Epoch 00001: val_loss improved from 6.96271 to 0.96825, saving model to model/model_0.hdf5\n",
      "809885/809885 [==============================] - 10s - loss: 2.1106 - mean_squared_error: 2.1106 - val_loss: 0.9682 - val_mean_squared_error: 0.9682\n",
      "Epoch 3/60\n",
      "806912/809885 [============================>.] - ETA: 0s - loss: 0.8770 - mean_squared_error: 0.8770Epoch 00002: val_loss improved from 0.96825 to 0.84506, saving model to model/model_0.hdf5\n",
      "809885/809885 [==============================] - 10s - loss: 0.8768 - mean_squared_error: 0.8768 - val_loss: 0.8451 - val_mean_squared_error: 0.8451\n",
      "Epoch 4/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.7970 - mean_squared_error: 0.7970Epoch 00003: val_loss improved from 0.84506 to 0.80208, saving model to model/model_0.hdf5\n",
      "809885/809885 [==============================] - 10s - loss: 0.7970 - mean_squared_error: 0.7970 - val_loss: 0.8021 - val_mean_squared_error: 0.8021\n",
      "Epoch 5/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.7477 - mean_squared_error: 0.7477Epoch 00004: val_loss improved from 0.80208 to 0.77541, saving model to model/model_0.hdf5\n",
      "809885/809885 [==============================] - 10s - loss: 0.7477 - mean_squared_error: 0.7477 - val_loss: 0.7754 - val_mean_squared_error: 0.7754\n",
      "Epoch 6/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.7067 - mean_squared_error: 0.7067Epoch 00005: val_loss improved from 0.77541 to 0.75983, saving model to model/model_0.hdf5\n",
      "809885/809885 [==============================] - 10s - loss: 0.7067 - mean_squared_error: 0.7067 - val_loss: 0.7598 - val_mean_squared_error: 0.7598\n",
      "Epoch 7/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.6696 - mean_squared_error: 0.6696Epoch 00006: val_loss improved from 0.75983 to 0.74814, saving model to model/model_0.hdf5\n",
      "809885/809885 [==============================] - 10s - loss: 0.6695 - mean_squared_error: 0.6695 - val_loss: 0.7481 - val_mean_squared_error: 0.7481\n",
      "Epoch 8/60\n",
      "804864/809885 [============================>.] - ETA: 0s - loss: 0.6344 - mean_squared_error: 0.6344Epoch 00007: val_loss improved from 0.74814 to 0.74182, saving model to model/model_0.hdf5\n",
      "809885/809885 [==============================] - 10s - loss: 0.6345 - mean_squared_error: 0.6345 - val_loss: 0.7418 - val_mean_squared_error: 0.7418\n",
      "Epoch 9/60\n",
      "806912/809885 [============================>.] - ETA: 0s - loss: 0.5993 - mean_squared_error: 0.5993Epoch 00008: val_loss improved from 0.74182 to 0.73874, saving model to model/model_0.hdf5\n",
      "809885/809885 [==============================] - 10s - loss: 0.5992 - mean_squared_error: 0.5992 - val_loss: 0.7387 - val_mean_squared_error: 0.7387\n",
      "Epoch 10/60\n",
      "806912/809885 [============================>.] - ETA: 0s - loss: 0.5639 - mean_squared_error: 0.5639Epoch 00009: val_loss did not improve\n",
      "809885/809885 [==============================] - 10s - loss: 0.5639 - mean_squared_error: 0.5639 - val_loss: 0.7390 - val_mean_squared_error: 0.7390\n",
      "Epoch 11/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.5277 - mean_squared_error: 0.5277Epoch 00010: val_loss did not improve\n",
      "809885/809885 [==============================] - 10s - loss: 0.5277 - mean_squared_error: 0.5277 - val_loss: 0.7405 - val_mean_squared_error: 0.7405\n",
      "Epoch 12/60\n",
      "806912/809885 [============================>.] - ETA: 0s - loss: 0.4912 - mean_squared_error: 0.4912Epoch 00011: val_loss did not improve\n",
      "809885/809885 [==============================] - 10s - loss: 0.4911 - mean_squared_error: 0.4911 - val_loss: 0.7443 - val_mean_squared_error: 0.7443\n",
      "Epoch 13/60\n",
      "806912/809885 [============================>.] - ETA: 0s - loss: 0.4548 - mean_squared_error: 0.4548Epoch 00012: val_loss did not improve\n",
      "809885/809885 [==============================] - 10s - loss: 0.4548 - mean_squared_error: 0.4548 - val_loss: 0.7513 - val_mean_squared_error: 0.7513\n",
      " 96256/100336 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "\n",
    "main(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "user_input (InputLayer)          (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "movie_input (InputLayer)         (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)         (None, 1, 6666)       40262640    user_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "embedding_22 (Embedding)         (None, 1, 6666)       40262640    movie_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)             (None, 6666)          0           embedding_21[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)             (None, 6666)          0           embedding_22[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)         (None, 1, 1)          6040        user_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "embedding_24 (Embedding)         (None, 1, 1)          3883        movie_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dot_6 (Dot)                      (None, 1)             0           flatten_21[0][0]                 \n",
      "                                                                   flatten_22[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)             (None, 1)             0           embedding_23[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)             (None, 1)             0           embedding_24[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "output (Add)                     (None, 1)             0           dot_6[0][0]                      \n",
      "                                                                   flatten_23[0][0]                 \n",
      "                                                                   flatten_24[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 80,535,203\n",
      "Trainable params: 80,535,203\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 809885 samples, validate on 89988 samples\n",
      "Epoch 1/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 11.7874 - mean_squared_error: 11.7874Epoch 00000: val_loss improved from inf to 6.60635, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 40s - loss: 11.7813 - mean_squared_error: 11.7813 - val_loss: 6.6063 - val_mean_squared_error: 6.6063\n",
      "Epoch 2/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 1.6823 - mean_squared_error: 1.6823Epoch 00001: val_loss improved from 6.60635 to 1.04644, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 1.6813 - mean_squared_error: 1.6813 - val_loss: 1.0464 - val_mean_squared_error: 1.0464\n",
      "Epoch 3/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.3327 - mean_squared_error: 0.3327Epoch 00002: val_loss did not improve\n",
      "809885/809885 [==============================] - 38s - loss: 0.3326 - mean_squared_error: 0.3326 - val_loss: 1.0681 - val_mean_squared_error: 1.0681\n",
      "Epoch 4/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0429 - mean_squared_error: 0.0429Epoch 00003: val_loss did not improve\n",
      "809885/809885 [==============================] - 38s - loss: 0.0429 - mean_squared_error: 0.0429 - val_loss: 1.0935 - val_mean_squared_error: 1.0935\n",
      "Epoch 5/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.1022 - mean_squared_error: 0.1022Epoch 00004: val_loss improved from 1.04644 to 1.04127, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.1022 - mean_squared_error: 0.1022 - val_loss: 1.0413 - val_mean_squared_error: 1.0413\n",
      "Epoch 6/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0732 - mean_squared_error: 0.0732Epoch 00005: val_loss did not improve\n",
      "809885/809885 [==============================] - 38s - loss: 0.0732 - mean_squared_error: 0.0732 - val_loss: 1.0493 - val_mean_squared_error: 1.0493\n",
      "Epoch 7/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0987 - mean_squared_error: 0.0987Epoch 00006: val_loss improved from 1.04127 to 1.01755, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0987 - mean_squared_error: 0.0987 - val_loss: 1.0176 - val_mean_squared_error: 1.0176\n",
      "Epoch 8/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0862 - mean_squared_error: 0.0862Epoch 00007: val_loss improved from 1.01755 to 1.01665, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0862 - mean_squared_error: 0.0862 - val_loss: 1.0167 - val_mean_squared_error: 1.0167\n",
      "Epoch 9/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0914 - mean_squared_error: 0.0914Epoch 00008: val_loss improved from 1.01665 to 0.98916, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0914 - mean_squared_error: 0.0914 - val_loss: 0.9892 - val_mean_squared_error: 0.9892\n",
      "Epoch 10/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0871 - mean_squared_error: 0.0871Epoch 00009: val_loss improved from 0.98916 to 0.98832, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0871 - mean_squared_error: 0.0871 - val_loss: 0.9883 - val_mean_squared_error: 0.9883\n",
      "Epoch 11/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0852 - mean_squared_error: 0.0852Epoch 00010: val_loss improved from 0.98832 to 0.96880, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0852 - mean_squared_error: 0.0852 - val_loss: 0.9688 - val_mean_squared_error: 0.9688\n",
      "Epoch 12/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0847 - mean_squared_error: 0.0847Epoch 00011: val_loss improved from 0.96880 to 0.96000, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0847 - mean_squared_error: 0.0847 - val_loss: 0.9600 - val_mean_squared_error: 0.9600\n",
      "Epoch 13/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0806 - mean_squared_error: 0.0806Epoch 00012: val_loss improved from 0.96000 to 0.94902, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0806 - mean_squared_error: 0.0806 - val_loss: 0.9490 - val_mean_squared_error: 0.9490\n",
      "Epoch 14/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0814 - mean_squared_error: 0.0814Epoch 00013: val_loss improved from 0.94902 to 0.93887, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0814 - mean_squared_error: 0.0814 - val_loss: 0.9389 - val_mean_squared_error: 0.9389\n",
      "Epoch 15/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0772 - mean_squared_error: 0.0772Epoch 00014: val_loss improved from 0.93887 to 0.92717, saving model to model/model_TA.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809885/809885 [==============================] - 41s - loss: 0.0771 - mean_squared_error: 0.0771 - val_loss: 0.9272 - val_mean_squared_error: 0.9272\n",
      "Epoch 16/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0783 - mean_squared_error: 0.0783Epoch 00015: val_loss improved from 0.92717 to 0.92121, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0783 - mean_squared_error: 0.0783 - val_loss: 0.9212 - val_mean_squared_error: 0.9212\n",
      "Epoch 17/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0744 - mean_squared_error: 0.0744Epoch 00016: val_loss improved from 0.92121 to 0.91117, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0744 - mean_squared_error: 0.0744 - val_loss: 0.9112 - val_mean_squared_error: 0.9112\n",
      "Epoch 18/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0756 - mean_squared_error: 0.0756Epoch 00017: val_loss improved from 0.91117 to 0.90065, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0756 - mean_squared_error: 0.0756 - val_loss: 0.9006 - val_mean_squared_error: 0.9006\n",
      "Epoch 19/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0722 - mean_squared_error: 0.0722Epoch 00018: val_loss improved from 0.90065 to 0.89488, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0722 - mean_squared_error: 0.0722 - val_loss: 0.8949 - val_mean_squared_error: 0.8949\n",
      "Epoch 20/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0730 - mean_squared_error: 0.0730Epoch 00019: val_loss improved from 0.89488 to 0.89019, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0729 - mean_squared_error: 0.0729 - val_loss: 0.8902 - val_mean_squared_error: 0.8902\n",
      "Epoch 21/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0700 - mean_squared_error: 0.0700Epoch 00020: val_loss improved from 0.89019 to 0.87883, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0700 - mean_squared_error: 0.0700 - val_loss: 0.8788 - val_mean_squared_error: 0.8788\n",
      "Epoch 22/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0701 - mean_squared_error: 0.0701Epoch 00021: val_loss improved from 0.87883 to 0.87548, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0701 - mean_squared_error: 0.0701 - val_loss: 0.8755 - val_mean_squared_error: 0.8755\n",
      "Epoch 23/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0681 - mean_squared_error: 0.0681Epoch 00022: val_loss improved from 0.87548 to 0.86937, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0681 - mean_squared_error: 0.0681 - val_loss: 0.8694 - val_mean_squared_error: 0.8694\n",
      "Epoch 24/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0675 - mean_squared_error: 0.0675Epoch 00023: val_loss improved from 0.86937 to 0.86321, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0675 - mean_squared_error: 0.0675 - val_loss: 0.8632 - val_mean_squared_error: 0.8632\n",
      "Epoch 25/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0662 - mean_squared_error: 0.0662Epoch 00024: val_loss improved from 0.86321 to 0.85716, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0662 - mean_squared_error: 0.0662 - val_loss: 0.8572 - val_mean_squared_error: 0.8572\n",
      "Epoch 26/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0654 - mean_squared_error: 0.0654Epoch 00025: val_loss improved from 0.85716 to 0.85355, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0654 - mean_squared_error: 0.0654 - val_loss: 0.8535 - val_mean_squared_error: 0.8535\n",
      "Epoch 27/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0644 - mean_squared_error: 0.0644Epoch 00026: val_loss improved from 0.85355 to 0.84818, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0644 - mean_squared_error: 0.0644 - val_loss: 0.8482 - val_mean_squared_error: 0.8482\n",
      "Epoch 28/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0632 - mean_squared_error: 0.0632Epoch 00027: val_loss improved from 0.84818 to 0.84341, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0632 - mean_squared_error: 0.0632 - val_loss: 0.8434 - val_mean_squared_error: 0.8434\n",
      "Epoch 29/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0628 - mean_squared_error: 0.0628Epoch 00028: val_loss improved from 0.84341 to 0.83838, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0628 - mean_squared_error: 0.0628 - val_loss: 0.8384 - val_mean_squared_error: 0.8384\n",
      "Epoch 30/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0616 - mean_squared_error: 0.0616Epoch 00029: val_loss improved from 0.83838 to 0.83561, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0615 - mean_squared_error: 0.0615 - val_loss: 0.8356 - val_mean_squared_error: 0.8356\n",
      "Epoch 31/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0611 - mean_squared_error: 0.0611Epoch 00030: val_loss improved from 0.83561 to 0.83069, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0611 - mean_squared_error: 0.0611 - val_loss: 0.8307 - val_mean_squared_error: 0.8307\n",
      "Epoch 32/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0601 - mean_squared_error: 0.0601Epoch 00031: val_loss improved from 0.83069 to 0.82869, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0601 - mean_squared_error: 0.0601 - val_loss: 0.8287 - val_mean_squared_error: 0.8287\n",
      "Epoch 33/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0596 - mean_squared_error: 0.0596Epoch 00032: val_loss improved from 0.82869 to 0.82319, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0596 - mean_squared_error: 0.0596 - val_loss: 0.8232 - val_mean_squared_error: 0.8232\n",
      "Epoch 34/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0588 - mean_squared_error: 0.0588Epoch 00033: val_loss improved from 0.82319 to 0.82028, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0588 - mean_squared_error: 0.0588 - val_loss: 0.8203 - val_mean_squared_error: 0.8203\n",
      "Epoch 35/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0581 - mean_squared_error: 0.0581Epoch 00034: val_loss improved from 0.82028 to 0.81420, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0581 - mean_squared_error: 0.0581 - val_loss: 0.8142 - val_mean_squared_error: 0.8142\n",
      "Epoch 36/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0574 - mean_squared_error: 0.0574Epoch 00035: val_loss did not improve\n",
      "809885/809885 [==============================] - 38s - loss: 0.0574 - mean_squared_error: 0.0574 - val_loss: 0.8156 - val_mean_squared_error: 0.8156\n",
      "Epoch 37/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0569 - mean_squared_error: 0.0569Epoch 00036: val_loss improved from 0.81420 to 0.81033, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0569 - mean_squared_error: 0.0569 - val_loss: 0.8103 - val_mean_squared_error: 0.8103\n",
      "Epoch 38/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0562 - mean_squared_error: 0.0562Epoch 00037: val_loss improved from 0.81033 to 0.80944, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0562 - mean_squared_error: 0.0562 - val_loss: 0.8094 - val_mean_squared_error: 0.8094\n",
      "Epoch 39/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0557 - mean_squared_error: 0.0557Epoch 00038: val_loss improved from 0.80944 to 0.80647, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0557 - mean_squared_error: 0.0557 - val_loss: 0.8065 - val_mean_squared_error: 0.8065\n",
      "Epoch 40/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0552 - mean_squared_error: 0.0552Epoch 00039: val_loss improved from 0.80647 to 0.80597, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0552 - mean_squared_error: 0.0552 - val_loss: 0.8060 - val_mean_squared_error: 0.8060\n",
      "Epoch 41/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0546 - mean_squared_error: 0.0546Epoch 00040: val_loss improved from 0.80597 to 0.80226, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0546 - mean_squared_error: 0.0546 - val_loss: 0.8023 - val_mean_squared_error: 0.8023\n",
      "Epoch 42/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0541 - mean_squared_error: 0.0541Epoch 00041: val_loss improved from 0.80226 to 0.80205, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0541 - mean_squared_error: 0.0541 - val_loss: 0.8021 - val_mean_squared_error: 0.8021\n",
      "Epoch 43/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0537 - mean_squared_error: 0.0537Epoch 00042: val_loss improved from 0.80205 to 0.80005, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0537 - mean_squared_error: 0.0537 - val_loss: 0.8001 - val_mean_squared_error: 0.8001\n",
      "Epoch 44/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0532 - mean_squared_error: 0.0532Epoch 00043: val_loss improved from 0.80005 to 0.79889, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0532 - mean_squared_error: 0.0532 - val_loss: 0.7989 - val_mean_squared_error: 0.7989\n",
      "Epoch 45/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0527 - mean_squared_error: 0.0527Epoch 00044: val_loss improved from 0.79889 to 0.79743, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0527 - mean_squared_error: 0.0527 - val_loss: 0.7974 - val_mean_squared_error: 0.7974\n",
      "Epoch 46/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0523 - mean_squared_error: 0.0523Epoch 00045: val_loss improved from 0.79743 to 0.79623, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0523 - mean_squared_error: 0.0523 - val_loss: 0.7962 - val_mean_squared_error: 0.7962\n",
      "Epoch 47/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0518 - mean_squared_error: 0.0518Epoch 00046: val_loss improved from 0.79623 to 0.79293, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0518 - mean_squared_error: 0.0518 - val_loss: 0.7929 - val_mean_squared_error: 0.7929\n",
      "Epoch 48/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0515 - mean_squared_error: 0.0515Epoch 00047: val_loss did not improve\n",
      "809885/809885 [==============================] - 38s - loss: 0.0515 - mean_squared_error: 0.0515 - val_loss: 0.7931 - val_mean_squared_error: 0.7931\n",
      "Epoch 49/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0511 - mean_squared_error: 0.0511Epoch 00048: val_loss improved from 0.79293 to 0.79154, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0511 - mean_squared_error: 0.0511 - val_loss: 0.7915 - val_mean_squared_error: 0.7915\n",
      "Epoch 50/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0507 - mean_squared_error: 0.0507Epoch 00049: val_loss improved from 0.79154 to 0.78985, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0507 - mean_squared_error: 0.0507 - val_loss: 0.7898 - val_mean_squared_error: 0.7898\n",
      "Epoch 51/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0503 - mean_squared_error: 0.0503Epoch 00050: val_loss improved from 0.78985 to 0.78962, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0503 - mean_squared_error: 0.0503 - val_loss: 0.7896 - val_mean_squared_error: 0.7896\n",
      "Epoch 52/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0500 - mean_squared_error: 0.0500Epoch 00051: val_loss improved from 0.78962 to 0.78884, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0500 - mean_squared_error: 0.0500 - val_loss: 0.7888 - val_mean_squared_error: 0.7888\n",
      "Epoch 53/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0497 - mean_squared_error: 0.0497Epoch 00052: val_loss improved from 0.78884 to 0.78820, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0497 - mean_squared_error: 0.0497 - val_loss: 0.7882 - val_mean_squared_error: 0.7882\n",
      "Epoch 54/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0492 - mean_squared_error: 0.0492Epoch 00053: val_loss improved from 0.78820 to 0.78625, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0492 - mean_squared_error: 0.0492 - val_loss: 0.7863 - val_mean_squared_error: 0.7863\n",
      "Epoch 55/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0490 - mean_squared_error: 0.0490Epoch 00054: val_loss did not improve\n",
      "809885/809885 [==============================] - 38s - loss: 0.0490 - mean_squared_error: 0.0490 - val_loss: 0.7871 - val_mean_squared_error: 0.7871\n",
      "Epoch 56/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0486 - mean_squared_error: 0.0486Epoch 00055: val_loss improved from 0.78625 to 0.78414, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0486 - mean_squared_error: 0.0486 - val_loss: 0.7841 - val_mean_squared_error: 0.7841\n",
      "Epoch 57/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0484 - mean_squared_error: 0.0484Epoch 00056: val_loss did not improve\n",
      "809885/809885 [==============================] - 38s - loss: 0.0484 - mean_squared_error: 0.0484 - val_loss: 0.7857 - val_mean_squared_error: 0.7857\n",
      "Epoch 58/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0479 - mean_squared_error: 0.0479Epoch 00057: val_loss improved from 0.78414 to 0.78384, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0479 - mean_squared_error: 0.0479 - val_loss: 0.7838 - val_mean_squared_error: 0.7838\n",
      "Epoch 59/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0479 - mean_squared_error: 0.0479Epoch 00058: val_loss improved from 0.78384 to 0.78293, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0479 - mean_squared_error: 0.0479 - val_loss: 0.7829 - val_mean_squared_error: 0.7829\n",
      "Epoch 60/60\n",
      "808960/809885 [============================>.] - ETA: 0s - loss: 0.0473 - mean_squared_error: 0.0473Epoch 00059: val_loss improved from 0.78293 to 0.78262, saving model to model/model_TA.hdf5\n",
      "809885/809885 [==============================] - 41s - loss: 0.0473 - mean_squared_error: 0.0473 - val_loss: 0.7826 - val_mean_squared_error: 0.7826\n",
      " 96256/100336 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "main(1) # 6666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.2158637 ]\n",
      " [ 3.95276141]\n",
      " [ 3.9234283 ]\n",
      " ..., \n",
      " [ 1.63274825]\n",
      " [ 3.24265885]\n",
      " [ 4.03903723]]\n",
      "(100336, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import sys\n",
    "test_y=np.load('test_y_0.npy')\n",
    "test_y += np.load('test_y_1_1024.npy')\n",
    "test_y += np.load('test_y_1_128.npy')\n",
    "test_y += np.load('test_y_1_32.npy')\n",
    "test_y += np.load('test_y_1_4.npy')\n",
    "test_y += np.load('test_y_1_8192.npy')\n",
    "test_y += np.load('test_y_2.npy')\n",
    "test_y/=7\n",
    "print (test_y)\n",
    "print (test_y.shape)\n",
    "np.save('save/test_total.npy',test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DataManager()\n",
    "dm.write_file(np.load('save/test_total.npy'), './output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f885630f3817>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#print (f)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0muid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'UserID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MovieID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "f = pd.read_csv('data/train.csv')\n",
    "#print (f)\n",
    "uid = np.array(f.iloc[:]['UserID']).reshape(-1,1)\n",
    "mid = np.array(f.iloc[:]['MovieID']).reshape(-1,1)\n",
    "rat = np.array(f.iloc[:]['Rating']).reshape(-1,1)\n",
    "\n",
    "#print (uid)\n",
    "#print ('==============')\n",
    "#print (np.hstack((uid, mid, rat)))\n",
    "#print ('==============')\n",
    "#print (permutation(uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
